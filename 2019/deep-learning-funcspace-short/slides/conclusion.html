<!-- .slide: class="layout-2x1" -->

## The Function Space Operator

<div style="margin: 20px;">
    <q>
        What's better than a new idea is an operator
        <br>
        that turns old ideas into new ideas
    </q>
    <br>
    <p style="font-size: 80%">Max Welling (paraphrased)</p>
</div>

<div class="column-1 flex-col fragment">
    <div style="border: 10px solid lightsalmon; border-radius: 30px; margin: 20px; padding: 10px 200px 10px 200px;">
        The <strong>Function Space Operator:</strong>
        $$f: \mathcal X \to \mathbb R^S \Rightarrow FS(f): \mathcal X \times S \to \mathbb R$$
    </div>
</div>

<div class="column-2 flex-col fragment">
    <strong>Examples:</strong>
    <div class="flex-row">
        <div class="flex-col" style="flex: 1;">
            <div>Occupancy Network:</div>
            <div>$$FS\left(\mathcal X \to \mathbb [0, 1]^{\mathbb R^3}\right)$$</div>
        </div>
        <div class="flex-col" style="flex: 1;">
            <div>Texture Field:</div>
            <div>$$FS\left(\mathcal X \to (\mathbb R^3)^{\mathbb R^3})\right)$$</div>
        </div>
        <div class="flex-col" style="flex: 1;">
            <div>Occupancy Flow:</div>
            <div>$$FS\left(\mathcal X \to \mathbb [0, 1]^{\mathbb R^4}\right)$$</div></div>
        </div>
    </div>
    <!-- <ul>
        <li>Texture Field: $$FS(\mathcal X \to (\mathbb R^3)^{\mathbb R^3})$$</li>
        <li>Occupancy Flow: $$FS(\mathcal X \to \mathbb [0, 1]^{T \times N \times N \times N})$$</li>
    </ul> -->
</div>

---

<!-- .slide: class="layout-1x1" -->

## Conclusion

<div class="column-1 flex-col">
    <ul style="width:80%; align-self: center;">
        <li class="fragment"> 
            Deep learning in <strong>function space</strong>
            allows to efficiently represent <strong>high dimensional 3D-data</strong> (occupancy, texture, motion, ...)
        </li>
        <li class="fragment">
            In contrast to existing representations, our representations <strong>does not discretize</strong> during training
        </li>
        <li class="fragment">
            This drastically reduces the <strong>memory requirements</strong> during <strong>training</strong>
        </li>
        <li class="fragment">
            During <strong>inference</strong> we can use fast <strong>specialized algorithms</strong>
        </li>
        <!-- <li class="fragment">
            Our technique is applicable to both <strong>generative</strong> and <strong>discriminative</strong> tasks
        </li> -->
    </ul>
</div>

---

<!-- .slide: class="layout-1x1" -->

## References

<div class="column-1 flex-col">
    <ul style="width:90%; align-self: center; font-size: 90%">
        <li>
            <strong>L. Mescheder</strong>, A. Geiger and S. Nowozin.
            Which Training Methods for GANs do actually Converge? 
            <span>(ICML 2018)</span>
        </li>
        <li>
            <strong>L. Mescheder</strong>, M. Oechsle, M. Niemeyer, S. Nowozin, and A. Geiger.
            Occupancy networks: Learning 3D Reconstruction in Function Space. 
            <span>(CVPR 2019)</span>
        </li>
        <li>
            M. Oechsle, <strong>L. Mescheder</strong>, M. Niemeyer, T. Strauss, and A. Geiger. 
            Texture Fields: Learning Texture Representations in Function Space.
            <span>(ICCV 2019)</span>
        </li>
        <li>
            M. Niemeyer, <strong>L. Mescheder</strong>, M. Oechsle, and A. Geiger.
            Occupancy Flow: 4D Reconstruction by Learning Particle Dynamics.
            <span>(ICCV 2019)</span>
        </li>
    </ul>
</div>

---

<div class="row-12 flex-row flex-center align-center" style="font-size: 2em">
    Thank you!
</div>